{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import math\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "   \n",
    "\n",
    "class TreeData(): \n",
    "    def __init__(self, tree_index, leaf_cutoff):\n",
    "        self.tree_index, self.leaf_cutoff = tree_index, leaf_cutoff\n",
    "        self._open_tree_data()\n",
    "\n",
    "        scales = [s for a,(s,p) in self.node_address.items()]\n",
    "        self.max_scale = np.max(scales)\n",
    "        self.min_scale = np.min(scales)\n",
    "        self.node_heatmap, self.heatmap_map, _ = self.create_heatmap(self.root)\n",
    "        self._open_baselines()\n",
    "\n",
    "    def _open_tree_data(self):\n",
    "        tree_dir = \"/localdata/sorel/covertrees/\"\n",
    "        with open(os.path.join(tree_dir, f\"tree_{self.leaf_cutoff}_{self.tree_index}_child_parent.json\")) as f:\n",
    "            self.child_parent = {int(k):int(v) for k,v in json.load(f).items()}\n",
    "        with open(os.path.join(tree_dir, f\"tree_{self.leaf_cutoff}_{self.tree_index}_node_address.json\")) as f:\n",
    "            self.node_address = {int(k):v for k,v in json.load(f).items()}\n",
    "        self.root = list(self.node_address.keys())[0]\n",
    "        while self.root in self.child_parent:\n",
    "            self.root = self.child_parent[self.root]\n",
    "        self.tree_layout = defaultdict(list)\n",
    "        for (child,parent) in self.child_parent.items():\n",
    "            self.tree_layout[int(parent)].append(child)\n",
    "\n",
    "    def _open_baselines(self):\n",
    "        baseline_dir = \"/localdata/sorel/covertrees/test_set_baselines/\"\n",
    "        tree_prefix = f\"tree_{self.leaf_cutoff}_{self.tree_index}_baseline_\"\n",
    "        filelist = os.listdir(baseline_dir)\n",
    "        self.baselines = {}\n",
    "        for fname in filelist:\n",
    "            if fname.startswith(tree_prefix):\n",
    "                sample_rate = fname[len(tree_prefix):-len(\".json\")].split(\"_\")[0]\n",
    "                with open(os.path.join(baseline_dir, fname)) as f:\n",
    "                    self.baselines[int(sample_rate)] = json.load(f)\n",
    "\n",
    "    def _value_heatmap(self, vals):\n",
    "        final_heatmap = np.zeros((self.node_heatmap.shape[0], self.node_heatmap.shape[1]))\n",
    "        for ad, val in vals.items():\n",
    "            ha = self.heatmap_map[ad]\n",
    "            for h in ha:\n",
    "                final_heatmap[h[0],h[1]] = val\n",
    "        return np.array(final_heatmap)\n",
    "\n",
    "    def create_heatmap(self, root):\n",
    "        def square_array(array):\n",
    "            max_width = 0\n",
    "            for a in array:\n",
    "                if len(a) > max_width:\n",
    "                    max_width = len(a)\n",
    "            for a in array:\n",
    "                while len(a) < max_width:\n",
    "                    a.append(0)\n",
    "            return array\n",
    "        \n",
    "        node_heatmap = [[] for i in range(self.max_scale - self.min_scale + 1)]\n",
    "        heatmap_map = defaultdict(list)\n",
    "        included_nodes = set()\n",
    "        unvisited_nodes = [root]\n",
    "        while 0 < len(unvisited_nodes):\n",
    "            node = unvisited_nodes.pop()\n",
    "            included_nodes.add(node)\n",
    "            if node in self.tree_layout:\n",
    "                for child in self.tree_layout[node]:\n",
    "                    unvisited_nodes.append(child)\n",
    "            else:\n",
    "                scale_index = max(self.node_address[node][0], self.min_scale)\n",
    "                heatmap_map[node].append([self.max_scale - scale_index, len(node_heatmap[self.max_scale - scale_index])])\n",
    "                node_heatmap[self.max_scale - scale_index].append(0)\n",
    "                while node in self.child_parent:\n",
    "                    node = self.child_parent[node]\n",
    "                    scale_index = max(self.node_address[node][0], self.min_scale)\n",
    "                    heatmap_map[node].append([self.max_scale - scale_index, len(node_heatmap[self.max_scale - scale_index])])\n",
    "                    node_heatmap[self.max_scale - scale_index].append(0)\n",
    "                node_heatmap = square_array(node_heatmap)\n",
    "        return np.array(node_heatmap), heatmap_map, included_nodes\n",
    "\n",
    "    def attack_set(self, attack_index, model_index):\n",
    "        return TreeAttackSet(self, attack_index, model_index)\n",
    "\n",
    "    def baseline(self, sample_rate):\n",
    "        return Baseline(self, self.baselines[sample_rate])\n",
    "\n",
    "    def path_to_node(self, node):\n",
    "        path = [node]\n",
    "        while node in self.child_parent:\n",
    "            node = self.child_parent[node]\n",
    "            path.insert(0, node)\n",
    "        return path\n",
    "\n",
    "class TreeAttackSet():\n",
    "    def __init__(self, tree, attack_index, model_index):\n",
    "        self.tree = tree\n",
    "        self.attack_index, self.model_index = attack_index, model_index\n",
    "        attack_dir = \"/localdata/sorel/covertrees/test_set_attack_results/\"\n",
    "        attack_prefix = f\"model_{model_index}_tree_{self.tree.leaf_cutoff}_{self.tree.tree_index}_attack_{attack_index}_\"\n",
    "        filelist = os.listdir(attack_dir)\n",
    "        self.attack_set = defaultdict(dict)\n",
    "        for fname in filelist:\n",
    "            if fname.startswith(attack_prefix) and \"path\" not in fname:\n",
    "                attack_rate, sample_rate = fname[len(attack_prefix):-len(\".json\")].split(\"_\")\n",
    "                with open(os.path.join(attack_dir, fname)) as f:\n",
    "                    self.attack_set[float(attack_rate)][int(sample_rate)] = json.load(f)\n",
    "\n",
    "        with open(os.path.join(attack_dir, attack_prefix + \"attack_path.json\")) as f:\n",
    "            self.path = [int(i) for i in json.load(f)]\n",
    "\n",
    "        self.attack_rates = list(self.attack_set.keys())\n",
    "        self.attack_rates = sorted(self.attack_rates)\n",
    "\n",
    "        self.sample_rates = list(self.attack_set[self.attack_rates[0]].keys())\n",
    "        self.sample_rates = sorted(self.sample_rates)\n",
    "\n",
    "    def tree_plot(self, val_type):\n",
    "        fig, ax = plt.subplots(len(self.attack_set),len(self.attack_set[0]))\n",
    "        for i,ar in enumerate(self.attack_rates):\n",
    "            for j,sr in enumerate(self.sample_rates):\n",
    "                all_results = self.attack(ar,sr).val_map(val_type)\n",
    "                pos = ax[i,j].imshow(self.tree._value_heatmap(all_results), aspect=\"auto\")\n",
    "                ax[i,j].set_xlabel(f\"{ar}, {sr}\")\n",
    "                fig.colorbar(pos, ax=ax[i,j])\n",
    "        fig.set_size_inches(30, 40)\n",
    "        plt.show()\n",
    "\n",
    "    def corrected_tree_plot(self, val_type):\n",
    "        fig, ax = plt.subplots(len(self.attack_set),len(self.attack_set[0]))\n",
    "        for i,ar in enumerate(self.attack_rates):\n",
    "            for j,sr in enumerate(self.sample_rates):\n",
    "                all_results = self.attack(ar,sr).corrected_val_map(val_type)\n",
    "                pos = ax[i,j].imshow(self.tree._value_heatmap(all_results), aspect=\"auto\")\n",
    "                ax[i,j].set_xlabel(f\"{ar}, {sr}\")\n",
    "                fig.colorbar(pos, ax=ax[i,j])\n",
    "        fig.set_size_inches(50, 40)\n",
    "        plt.show()\n",
    "\n",
    "    def attack(self, attack_rate, sample_rate):\n",
    "        results = self.attack_set[attack_rate][sample_rate]\n",
    "        return TreeAttack(self, self.tree, results, self.tree.baseline(sample_rate))\n",
    "\n",
    "    def true_attack_path(self):\n",
    "        return self.path\n",
    "\n",
    "class TreeAttack():\n",
    "    def __init__(self, attack, tree, results, baseline):\n",
    "        self.tree, self.attack, self.results, self.baseline = tree, attack, results, baseline\n",
    "\n",
    "    def mll(self):\n",
    "        self.results[\"overall_tracker\"][\"mll\"]\n",
    "\n",
    "    def kl_div(self):\n",
    "        self.results[\"overall_tracker\"][\"kl_div\"]\n",
    "\n",
    "    def tree_plot(self, val_type):\n",
    "        fig, ax = plt.subplots(1)\n",
    "        all_results = self.val_map(val_type)\n",
    "        pos = ax.imshow(self.tree._value_heatmap(all_results), aspect=\"auto\")\n",
    "        fig.colorbar(pos, ax=ax)\n",
    "        fig.set_size_inches(50, 20)\n",
    "        plt.show()\n",
    "    \n",
    "    def corrected_tree_plot(self, val_type):\n",
    "        fig, ax = plt.subplots(1)\n",
    "        all_results = self.corrected_val_map(val_type)\n",
    "        pos = ax.imshow(self.tree._value_heatmap(all_results), aspect=\"auto\")\n",
    "        fig.colorbar(pos, ax=ax)\n",
    "        fig.set_size_inches(50, 20)\n",
    "        plt.show()\n",
    "\n",
    "    def corrected_val_map(self, val_type, correction_factor = 0):\n",
    "        return {int(k): self.baseline(int(k), val_type, r[val_type], correction_factor) for k,r in self.results[\"node_trackers\"].items()}\n",
    "    \n",
    "    def val_map(self, val_type):\n",
    "        return {int(k): r[val_type] for k,r in self.results[\"node_trackers\"].items()}\n",
    "\n",
    "    def true_attack_path(self):\n",
    "        return self.attack.path\n",
    "\n",
    "class Baseline():\n",
    "    def __init__(self, tree, baseline):\n",
    "        self.node_baselines = {int(k):v for k,v in baseline[\"node_baselines\"].items()}\n",
    "        self.overall_baseline = baseline[\"overall_baseline\"]\n",
    "        self.tree, self.baseline = tree, baseline\n",
    "    \n",
    "    def __call__(self, address, val_type, value, correction_factor = 0):\n",
    "        if address in self.node_baselines:\n",
    "            base_mean = self.node_baselines[address][f\"mean_{val_type}\"]\n",
    "            base_max = self.node_baselines[address][f\"max_{val_type}\"]\n",
    "            return value - base_max - correction_factor*(base_max - base_mean)\n",
    "        else:\n",
    "            return value\n",
    "\n",
    "    def overall(self, val_type):\n",
    "        return self.overall_baseline[f\"mean_{val_type}\"], self.overall_baseline[f\"max_{val_type}\"]\n",
    "\n",
    "class AllData():\n",
    "    def __init__(self, limit=48):\n",
    "        tree_dir = \"/localdata/sorel/covertrees/\"\n",
    "        attack_dir = \"/localdata/sorel/covertrees/test_set_attack_results/\"\n",
    "\n",
    "        self.trees = {}\n",
    "        self.attack_sets = {}\n",
    "        self.attacks = defaultdict(lambda: defaultdict(list))\n",
    "        for tree_name in os.listdir(tree_dir):\n",
    "            if \"test\" in tree_name:\n",
    "                continue\n",
    "            p = tree_name.split(\".\")[0].split(\"_\")\n",
    "            leaf_cutoff, tree_index = int(p[1]), int(p[2])\n",
    "            if tree_index < limit:\n",
    "                self.trees[(tree_index, leaf_cutoff)] = TreeData(tree_index, leaf_cutoff)\n",
    "        \n",
    "        for attack_name in os.listdir(attack_dir):\n",
    "            if \"path\" in attack_name:\n",
    "                continue\n",
    "            p = attack_name[:-len(\".json\")].split(\"_\")\n",
    "            model_index, leaf_cutoff, tree_index, attack_index, attack_rate, sample_rate = int(p[1]), int(p[3]), int(p[4]), int(p[6]), float(p[7]), int(p[8])\n",
    "            if (tree_index, leaf_cutoff) not in self.trees:\n",
    "                continue\n",
    "            if (tree_index, leaf_cutoff, model_index, attack_index) in self.attack_sets:\n",
    "                attack_set = self.attack_sets[(tree_index, leaf_cutoff, model_index, attack_index)]\n",
    "            else:\n",
    "                attack_set = self.trees[(tree_index, leaf_cutoff)].attack_set(attack_index, model_index)\n",
    "                self.attack_sets[(tree_index, leaf_cutoff, model_index, attack_index)] = attack_set\n",
    "            self.attacks[attack_rate][sample_rate].append(attack_set.attack(attack_rate, sample_rate))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attack_data = AllData(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def predict_attack(attack_vals, correction):\n",
    "    max_val = 0.0\n",
    "    max_addr = None\n",
    "    for k,v in attack_vals.items():\n",
    "        if v - correction > max_val:\n",
    "            max_val = v\n",
    "            max_addr = k\n",
    "    return max_addr\n",
    "\n",
    "def prediction_efficacy(value_type, prediction_correction_factor, baseline_correction_factor):\n",
    "    attack_rates = [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "    sample_rates = [1000, 10000, 100000]\n",
    "\n",
    "    efficacy = defaultdict(lambda: defaultdict(list))\n",
    "    failures = defaultdict(lambda: defaultdict(list))\n",
    "    misses = defaultdict(lambda: defaultdict(list))\n",
    "    for ar in attack_rates:\n",
    "        for sr in sample_rates:\n",
    "            success = 0\n",
    "            failure = 0\n",
    "            total = 0\n",
    "            for attack in attack_data.attacks[ar][sr]:\n",
    "                predicted_attack = predict_attack(attack.corrected_val_map(value_type, baseline_correction_factor), prediction_correction_factor)\n",
    "                if predicted_attack in attack.true_attack_path():\n",
    "                    success += 1\n",
    "                elif predicted_attack is not None:\n",
    "                    failure += 1\n",
    "                    failures[ar][sr].append(attack)\n",
    "                else:\n",
    "                    misses[ar][sr].append(attack)\n",
    "                total += 1\n",
    "            efficacy[ar][sr] = (float(success)/ total, float(failure)/total)\n",
    "\n",
    "    return pd.DataFrame(efficacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paired_prediction_efficacy(hyper):\n",
    "    attack_rates = [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0]\n",
    "    sample_rates = [1000, 10000, 100000]\n",
    "\n",
    "    efficacy = defaultdict(lambda: defaultdict(list))\n",
    "    for ar in attack_rates:\n",
    "        for sr in sample_rates:\n",
    "            success = 0\n",
    "            failure = 0\n",
    "            total = 0\n",
    "            for attack in attack_data.attacks[ar][sr]:\n",
    "                kl_predicted_attack = predict_attack(attack.corrected_val_map(\"kl_div\", hyper[sr][\"kl_core\"]), hyper[sr][\"kl_str\"])\n",
    "                if kl_predicted_attack in attack.true_attack_path():\n",
    "                    success += 1\n",
    "                elif kl_predicted_attack is not None:\n",
    "                    failure += 1\n",
    "                else:\n",
    "                    mll_predicted_attack = predict_attack(attack.corrected_val_map(\"mll\", hyper[sr][\"mll_core\"]), hyper[sr][\"mll_str\"])\n",
    "                    if mll_predicted_attack in attack.true_attack_path():\n",
    "                        success += 1\n",
    "                    elif mll_predicted_attack is not None:\n",
    "                        failure += 1\n",
    "                total += 1\n",
    "            efficacy[ar][sr] = (float(success)/ total, float(failure)/total)\n",
    "\n",
    "    return pd.DataFrame(efficacy)\n",
    "hyper = {\n",
    "    1000:  {\"kl_str\": 3, \"kl_core\":4.5, \"mll_str\":11, \"mll_core\":4.5},\n",
    "    10000: {\"kl_str\": 5, \"kl_core\":3, \"mll_str\":14, \"mll_core\":3.5},\n",
    "    100000: {\"kl_str\": 6, \"kl_core\":3, \"mll_str\":17, \"mll_core\":2.5}}\n",
    "paired_prediction_efficacy(hyper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "def ml_kl_scatter(ar,sr):\n",
    "    X = []\n",
    "    Y = []\n",
    "    A = []\n",
    "    B = []\n",
    "    fix, (ax1, ax2) = plt.subplots(2)\n",
    "    for attack in attack_data.attacks[ar][sr]:\n",
    "        for a, v in attack.val_map(\"kl_div\").items():\n",
    "            if a in attack.baseline.node_baselines and v - attack.baseline.node_baselines[a][\"max_kl_div\"] > 0:\n",
    "                baseline = attack.baseline.node_baselines[a]\n",
    "                Y.append(v - baseline[\"max_kl_div\"])\n",
    "                X.append(baseline[\"max_kl_div\"] - baseline[\"mean_kl_div\"])\n",
    "        for a, v in attack.val_map(\"mll\").items():\n",
    "            if a in attack.baseline.node_baselines and v - attack.baseline.node_baselines[a][\"max_mll\"] > 0:\n",
    "                baseline = attack.baseline.node_baselines[a]\n",
    "                B.append(v - baseline[\"max_mll\"])\n",
    "                A.append(baseline[\"max_mll\"] - baseline[\"mean_mll\"])\n",
    "                \n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    A = np.array(A)\n",
    "    B = np.array(B)\n",
    "    X = X.flatten()\n",
    "    ax1.scatter(A, B, color=\"orange\")\n",
    "    ax2.scatter(X, Y)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_kl_scatter(0.0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_kl_scatter(0.0,10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_kl_scatter(0.0,100000)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "117d04ed8c83fab976f8d76651447fcb732a17f54ec11e1c7d4863a9f33c7159"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('goko': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
