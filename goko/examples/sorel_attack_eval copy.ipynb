{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class TreeData(): \n",
    "    def __init__(self, tree_index, leaf_cutoff):\n",
    "        self.tree_index, self.leaf_cutoff = tree_index, leaf_cutoff\n",
    "        self._open_tree_data()\n",
    "\n",
    "        scales = [s for a,(s,p) in self.node_address.items()]\n",
    "        self.max_scale = np.max(scales)\n",
    "        self.min_scale = np.min(scales)\n",
    "        self._node_heatmap, self._heatmap_map = None, None\n",
    "    \n",
    "    def _open_tree_data(self):\n",
    "        tree_dir = \"/localdata/sorel/covertrees/\"\n",
    "        with open(os.path.join(tree_dir, f\"tree_{self.leaf_cutoff}_{self.tree_index}_child_parent.json\")) as f:\n",
    "            self.child_parent = {int(k):int(v) for k,v in json.load(f).items()}\n",
    "        with open(os.path.join(tree_dir, f\"tree_{self.leaf_cutoff}_{self.tree_index}_node_address.json\")) as f:\n",
    "            self.node_address = {int(k):v for k,v in json.load(f).items()}\n",
    "        self.root = list(self.node_address.keys())[0]\n",
    "        while self.root in self.child_parent:\n",
    "            self.root = self.child_parent[self.root]\n",
    "        self.tree_layout = defaultdict(list)\n",
    "        for (child,parent) in self.child_parent.items():\n",
    "            self.tree_layout[int(parent)].append(child)\n",
    "\n",
    "    def _value_heatmap(self, vals):\n",
    "        if self._node_heatmap is None:\n",
    "            self._node_heatmap, self._heatmap_map, _ = self.create_heatmap(self.root)\n",
    "\n",
    "        final_heatmap = np.zeros((self.node_heatmap.shape[0], self.node_heatmap.shape[1]))\n",
    "        for ad, val in vals.items():\n",
    "            ha = self.heatmap_map[ad]\n",
    "            for h in ha:\n",
    "                final_heatmap[h[0],h[1]] = val\n",
    "        return np.array(final_heatmap)\n",
    "\n",
    "    def create_heatmap(self, root):\n",
    "        def square_array(array):\n",
    "            max_width = 0\n",
    "            for a in array:\n",
    "                if len(a) > max_width:\n",
    "                    max_width = len(a)\n",
    "            for a in array:\n",
    "                while len(a) < max_width:\n",
    "                    a.append(0)\n",
    "            return array\n",
    "        \n",
    "        node_heatmap = [[] for i in range(self.max_scale - self.min_scale + 1)]\n",
    "        heatmap_map = defaultdict(list)\n",
    "        included_nodes = set()\n",
    "        unvisited_nodes = [root]\n",
    "        while 0 < len(unvisited_nodes):\n",
    "            node = unvisited_nodes.pop()\n",
    "            included_nodes.add(node)\n",
    "            if node in self.tree_layout:\n",
    "                for child in self.tree_layout[node]:\n",
    "                    unvisited_nodes.append(child)\n",
    "            else:\n",
    "                scale_index = max(self.node_address[node][0], self.min_scale)\n",
    "                heatmap_map[node].append([self.max_scale - scale_index, len(node_heatmap[self.max_scale - scale_index])])\n",
    "                node_heatmap[self.max_scale - scale_index].append(0)\n",
    "                while node in self.child_parent:\n",
    "                    node = self.child_parent[node]\n",
    "                    scale_index = max(self.node_address[node][0], self.min_scale)\n",
    "                    heatmap_map[node].append([self.max_scale - scale_index, len(node_heatmap[self.max_scale - scale_index])])\n",
    "                    node_heatmap[self.max_scale - scale_index].append(0)\n",
    "                node_heatmap = square_array(node_heatmap)\n",
    "        return np.array(node_heatmap), heatmap_map, included_nodes\n",
    "\n",
    "    def path_to_node(self, node):\n",
    "        path = [node]\n",
    "        while node in self.child_parent:\n",
    "            node = self.child_parent[node]\n",
    "            path.insert(0, node)\n",
    "        return path\n",
    "    \n",
    "    def baseline(self, sample_rate):\n",
    "        return BayesianBaseline(self, sample_rate)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attack():\n",
    "    def __init__(self, baseline, attack, path):\n",
    "        self.baseline, self.attack, self.true_path = baseline, attack, path\n",
    "\n",
    "    def kl_divs_predict(self):\n",
    "        max_val = 0.0\n",
    "        max_addr = None\n",
    "        for k,v in self.attack[\"node_trackers\"].items():\n",
    "            if self.baseline.kl_div_baseline(k) is None:\n",
    "                continue\n",
    "\n",
    "            max_kl_div, std_kl_div = self.baseline.kl_div_baseline(k)\n",
    "            corrected_kl_div = v[\"kl_div\"] - max_kl_div - self.baseline.kl_cor * std_kl_div  - self.baseline.kl_str\n",
    "            if corrected_kl_div > max_val:\n",
    "                #print(f'KL_DIV {corrected_kl_div} = {v[\"kl_div\"]} - {max_kl_div} - {self.baseline.kl_cor} * {std_kl_div}  - {self.baseline.kl_str}')\n",
    "                max_val = corrected_kl_div\n",
    "                max_addr = k\n",
    "        return max_addr\n",
    "\n",
    "    def mlls_predict(self):\n",
    "        max_val = 0.0\n",
    "        max_addr = None\n",
    "        for k,v in self.attack[\"node_trackers\"].items():\n",
    "            if self.baseline.mll_baseline(k) is None:\n",
    "                continue\n",
    "            min_mll, std_mll = self.baseline.mll_baseline(k)\n",
    "            corrected_mll = min_mll - v[\"mll\"] - self.baseline.mll_cor * std_mll - self.baseline.mll_str\n",
    "            if corrected_mll > max_val:\n",
    "                #print(f'MLL {corrected_mll} = {min_mll} - {v[\"mll\"]} - {self.baseline.mll_cor} * {std_mll}  - {self.baseline.mll_str}')\n",
    "                max_val = corrected_mll\n",
    "                max_addr = k\n",
    "        return max_addr\n",
    "\n",
    "    def predict_attack(self):\n",
    "        kl_prediction = self.kl_divs_predict()\n",
    "        if kl_prediction is None:\n",
    "            return self.mlls_predict()\n",
    "        else:\n",
    "            return kl_prediction\n",
    "            \n",
    "class BayesianBaseline():\n",
    "    def __init__(self, *, sample_rate, tree=None, leaf_cutoff=None, tree_index=None):\n",
    "        self.leaf_cutoff, self.tree_index, self.sample_rate = leaf_cutoff, tree_index, sample_rate\n",
    "        self._tree = tree\n",
    "        baseline_dir = \"/localdata/sorel/covertrees/test_set_baselines\"\n",
    "        baseline_file = f\"tree_{self.leaf_cutoff}_{self.tree_index}_baseline_{self.sample_rate}.json\"\n",
    "        with open(os.path.join(baseline_dir, baseline_file)) as f:\n",
    "            self.baseline = json.load(f)\n",
    "        self.baseline[\"node_baselines\"] = {int(k): v for k,v in self.baseline[\"node_baselines\"].items()}\n",
    "        self._loo_violators = None\n",
    "    \n",
    "    @property\n",
    "    def tree(self):\n",
    "        if self._tree is None:\n",
    "            self._tree = TreeData(self.tree_index, self.leaf_cutoff)\n",
    "\n",
    "    def attacks(self, attack_rate, model_indices=range(5), attack_indices=range(10)):\n",
    "        attacks = []\n",
    "        attack_dir = \"/localdata/sorel/covertrees/test_set_attack_results\"\n",
    "        for model_index in model_indices:\n",
    "            for attack_index in attack_indices:\n",
    "                try:\n",
    "                    attack_filename = f\"model_{model_index}_tree_{self.leaf_cutoff}_{self.tree_index}_attack_{attack_index}_{attack_rate}_{self.sample_rate}.json\"\n",
    "                    path_filename = f\"model_{model_index}_tree_{self.leaf_cutoff}_{self.tree_index}_attack_{attack_index}_attack_path.json\"\n",
    "                    with open(os.path.join(attack_dir, attack_filename)) as f:\n",
    "                        attack = json.load(f)\n",
    "                    attack[\"node_trackers\"] = {int(k): v for k,v in attack[\"node_trackers\"].items()}\n",
    "                    with open(os.path.join(attack_dir, path_filename)) as f:\n",
    "                        path = [int(i) for i in json.load(f)]\n",
    "                    attacks.append(Attack(self, attack, path))\n",
    "                except:\n",
    "                    pass\n",
    "        return attacks\n",
    "\n",
    "    def set_prediction_hypers(self,*,kl_str, kl_cor, mll_str, mll_cor):\n",
    "        self.kl_str, self.kl_cor, self.mll_str, self.mll_cor = kl_str, kl_cor, mll_str, mll_cor\n",
    "\n",
    "    def mll_baseline(self, address=None):\n",
    "        if address is None:\n",
    "            return self.baseline[\"overall_baseline\"]\n",
    "        else:\n",
    "            if address in self.baseline[\"node_baselines\"]:\n",
    "                baseline = self.baseline[\"node_baselines\"][address]\n",
    "                return baseline[\"min_mll\"], baseline[\"std_mll\"]\n",
    "            else:\n",
    "                return None\n",
    "\n",
    "    def kl_div_baseline(self, address=None):\n",
    "        if address is None:\n",
    "            return self.baseline[\"overall_baseline\"]\n",
    "        else:\n",
    "            if address in self.baseline[\"node_baselines\"]:\n",
    "                baseline = self.baseline[\"node_baselines\"][address]\n",
    "                return baseline[\"max_kl_div\"], baseline[\"std_kl_div\"]\n",
    "            else:\n",
    "                return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stats_for_sample_rate(sample_rate, *, kl_str, kl_cor, mll_str, mll_cor):\n",
    "    attack_rates = [0, 0.0001, 0.001, 0.01, 0.1, 1]\n",
    "    successes = {ar: 0 for ar in attack_rates}\n",
    "    penetration = {ar: 0 for ar in attack_rates}\n",
    "    failures = {ar: 0 for ar in attack_rates}\n",
    "    total = {ar: 0 for ar in attack_rates}\n",
    "\n",
    "    overall_kl_div = {ar: [] for ar in attack_rates}\n",
    "    overall_mll = {ar: [] for ar in attack_rates}\n",
    "    for tree_index in range(48):\n",
    "        baseline = BayesianBaseline(sample_rate=sample_rate, leaf_cutoff=500, tree_index=tree_index)\n",
    "        baseline.set_prediction_hypers(kl_str=kl_str,kl_cor=kl_cor,mll_str=mll_str, mll_cor=mll_cor)\n",
    "        for attack_rate in attack_rates:\n",
    "            for attack in baseline.attacks(attack_rate):\n",
    "                overall_kl_div[attack_rate].append(attack.attack[\"overall_tracker\"][\"kl_div\"])\n",
    "                overall_mll[attack_rate].append(attack.attack[\"overall_tracker\"][\"mll\"])\n",
    "                pred = attack.predict_attack()\n",
    "                if pred in attack.true_path:\n",
    "                    penetration[attack_rate] += float(attack.true_path.index(pred))/len(attack.true_path)\n",
    "                    successes[attack_rate] += 1\n",
    "                elif pred is not None:\n",
    "                    failures[attack_rate] += 1\n",
    "                total[attack_rate] += 1\n",
    "    return successes, penetration, failures, total, overall_kl_div, overall_mll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_100000 = stats_for_sample_rate(100000,kl_str=40,kl_cor=10,mll_str=50, mll_cor=1.7)\n",
    "stats_100000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_10000 = stats_for_sample_rate(10000, kl_str=6.5,kl_cor=10,mll_str=20, mll_cor=1.3)\n",
    "stats_10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_1000 = stats_for_sample_rate(1000, kl_str=8,kl_cor=7,mll_str=20, mll_cor=1.3)\n",
    "stats_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def attack_stats_to_table(attack_stats):\n",
    "    successes, penetration, failures, total, overall_kl_div, overall_mll = attack_stats\n",
    "    attack_table = {}\n",
    "    kl_div_table = {}\n",
    "    mll_table = {}\n",
    "    zero_false_positives = float(successes[0] + failures[0])/total[0]\n",
    "    zero_true_positives = 0\n",
    "    zero_mean_kl_div = np.mean(overall_kl_div[0])\n",
    "    zero_std_kl_div = np.sqrt(np.var(overall_kl_div[0]))\n",
    "    zero_mean_mll = np.mean(overall_mll[0])\n",
    "    zero_std_mll = np.sqrt(np.var(overall_mll[0]))\n",
    "    attack_table[0] = (zero_true_positives, zero_false_positives)\n",
    "    kl_div_table[0] = (0, 1)\n",
    "    mll_table[0] = (0, 1)\n",
    "    for ar in successes.keys():\n",
    "        if ar == 0:\n",
    "            continue\n",
    "        if successes[ar] > 0:\n",
    "            mean_penetration = float(penetration[ar])/successes[ar]\n",
    "        else:\n",
    "            mean_penetration = None\n",
    "        true_positives = float(successes[ar])/total[ar]\n",
    "        false_positives = float(failures[ar])/total[ar]\n",
    "        mean_kl_div = np.mean(overall_kl_div[ar])\n",
    "        std_kl_div = np.sqrt(np.var(overall_kl_div[ar]))\n",
    "        mean_mll = np.mean(overall_mll[ar])\n",
    "        std_mll = np.sqrt(np.var(overall_mll[ar]))\n",
    "        attack_table[ar] = (true_positives, false_positives, mean_penetration)\n",
    "        kl_div_table[ar] = ((mean_kl_div-zero_mean_kl_div)/zero_mean_kl_div, std_kl_div/zero_std_kl_div)\n",
    "        mll_table[ar] = ((mean_mll-zero_mean_mll)/zero_std_mll, std_mll/zero_std_mll)\n",
    "    return attack_table, kl_div_table, mll_table\n",
    "complete_attack_table, complete_kl_div_table, complete_mll_table = {}, {}, {}\n",
    "complete_attack_table[1000], complete_kl_div_table[1000], complete_mll_table[1000] = attack_stats_to_table(stats_1000)\n",
    "complete_attack_table[10000], complete_kl_div_table[10000], complete_mll_table[10000] = attack_stats_to_table(stats_10000)\n",
    "complete_attack_table[100000], complete_kl_div_table[100000], complete_mll_table[100000] = attack_stats_to_table(stats_100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_attack_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_kl_div_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_mll_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "117d04ed8c83fab976f8d76651447fcb732a17f54ec11e1c7d4863a9f33c7159"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 64-bit ('goko': pyenv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
